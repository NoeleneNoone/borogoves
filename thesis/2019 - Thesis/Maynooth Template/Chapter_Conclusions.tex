% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Conclusions}\label{ch:conc} % top level followed by section, subsection

% ----------------------- contents from here ------------------------
\begin{textsl}
{\small In this chapter, we review and summarise the work presented in this manuscript and provide
recommendations for possible extensions.}
\end{textsl}

\vspace*{1cm}

\section{Summary}
The work presented in this thesis looked at three aspects of software delivery to the Cloud: Software testing, Cloud outage modelling/simulation and chat discourse modelling \& segmentation.

Chapter 2 reviewed the field and the current state of related literature. Chapter 3 looked at how the customer can aid software testing in the realm of a rapid software release model. Additionally, in this chapter, we looked at the importance of internal software testing before release and proposed a method of crowdsourced testing. The technical contribution of this chapter can aid SMEs and micro teams to produce high-quality software while respecting their low level of resources.

Chapter 4 focused on modelling the inter-arrival and service times of Cloud outage events. By examining Cloud outage times, a suitable probability density distribution was found to model both inter-arrival and service times. We also looked at whether the distribution type varied by outage type and by software component. The core contribution to knowledge was the discovery that a Pareto distribution could be used to model outage inter-arrival times and a log-normal distribution could be used to model outage service times. The latter result fits well with previous research that states a log-normal distribution can be used to model service times of repairable systems. 

Chapter 5 takes the inter-arrival and service time distribution results from chapter 4 and uses this result to simulate Cloud outage events (in the form of busy times of a Queuing system). Furthermore we demonstrated that by using distributions modelled on outage inter-arrival and service times (i.e. a special case of a G/G/1 queue), a more accurate simulation could be achieved over an M/M/1 queue. By employing such a queue model framework, DevOps teams can build an precise planning model to ensure sufficient resources are available when a Cloud outage occurs.

Chapter 6 explored an analogue to outage service time by modelling and topic mining real-time group chat conversations. By analysing two distinct datasets we found that a suitable probability density distribution could be found to model conversation duration, delta, message inter-arrival time, and message line/user/word counts. We also found that the probability distribution is a function of message density. The findings of this work support previous studies in the field of chat discourse modelling. 

Chapter 7 considered the area of topic modelling within small text corpora. Through analysis of multiple threaded conversations, we considered a technique for corpus layering that allows a higher availability of words (between 15\% to 20\%) for topic modelling algorithms such as BiTerm and LDA. Furthermore, we demonstrated that this layering technique provides a more readable output than using an entire message corpus alone. The key benefit for small teams that produce large quantities of chat discourse is to aid the problem determination resolution by providing higher resolution topic term outputs.

Chapter 7 also considered Boundary Identification (to be completed in 2018)


\section{Future Works}

Many possible additions or improvements could build on this body of work.

As we saw in chapter 3, we proposed a bounty/reward system to incentivise customers to find defects within a given product. A useful extension would be to employ a system of Gamification\cite{huotari2012defining}. Gamification could be interesting here given the additional proposals of crowd-sourced testing; this would allow cohorts of testers to compete with each other to find the most bugs in a given time period. Adopting and measuring the efficacy of such a model could provide a higher degree of business intelligence to software manufacturers.

In chapter 4 we saw the benefits of how modelling inter-arrival and service times can be used to infer arrival and service remediation rates in general. With sufficient data points, SMEs and micro teams can target specific components and outage types. We acknowledge that, while a general distribution model is useful, a suite of models is of greater benefit to teams who want to first understand outage times within specific troublesome components and failure types.

An additional extension is an iterative approach to modelling failure times. For example, if teams want to understand fundamental questions such as: Are in the inter-arrival/service times of specific outages categories increasing or decreasing on a per release basis? Re-modelling on a regular basis would be useful.

Chapter 5 discussed how it is possible to use inter-arrival and service time distributions as a method to seed an M/M/1 queue to predict the busy time of teams using a simple queuing model. One natural extension of this work is to apply the approach in a queuing framework with multiple servers (i.e. an M/M/c queue). This addition appears intuitive given that; applications may have various components, failure types and data centre locations. Therefore by extending the model to predict team busy times at a specific data centre location, or within a particular sub-component or indeed based on a specific type of failure is beneficial. 

Teams can then be better positioned to deploy specific resources where they are most needed. Additionally, this future work may aid training and upskilling efforts within groups. Consider the scenario whereby, team busy times are known to be clustered around a common outage type or a protracted service time engagement. By surfacing this information technical leads and management can use this knowledge to investigate methods to either reduce the occurrence of frequent outage patterns and to reduce the service time to remediate parallel outages.

Chapter 6 provided a general framework to model the duration, delta and inter-arrival of segmented chat conversations. Possible extensions to this general framework are as follows: We know that current real-time chat offerings such as Slack, Teams and Watson Workspace, use the construct of channels or spaces to partition conversations based on topic. By adopting a hierarchal model, teams can analyse conversations at an organisation level. Additional there is value in modelling conservations whereby both topic and users are seen as the principal components of segmented conversations. Understanding expected conversation durations, for a given topic or when a specific cohort of individuals is involved, may help in the resolution of problems where real-time chat is the primary means of communication.

Chapter 7 demonstrated that by segmenting messages into burst and reflection pools, a larger number of words are available for topic model algorithms and that such modelling can lead to greater readability. We acknowledge that we used a simple set of criteria to define a burst and reflection. However, we know that message density is not the same in all message corpora and that imposing a one size fits all (generalised) solution is undesirable. Therefore we suggest two future extensions. Firstly by adopting an approach to unsupervised machine learning, a system can learn and define burst and reflection periods for a specific text corpus. Another extension to aid in this regard, is to understand what types of utterances lead to defining a burst and reflection period and to what extent subsequent messages are depending on an initial message.

Chapter 7  **Boundary Identification (to be completed in 2018)

\section{Final Thoughts}

From work presented over the course of this thesis, we have shown, that to employ rapid software delivery, software providers need not compromise on quality. By adopting a suite of techniques, we have demonstrated ways in which teams with a small number of resources can compete (regarding rapid delivery and quality) with larger corporations. 

Over the duration of this research, we have seen on the surface three seemingly unrelated topics converge into the thesis. This work is related to the way both Cloud and Continuous delivery is seen as a vehicle for the rapid software release. Software delivery was seen as the preserve of large corporations in times past. However, we know what the SME and micro team has a role to play in rapid software delivery given their contribution to the global economy \cite{WTO}.

The idea that customers are used to help test software they have paid for may seem unorthodox. Indeed, this viewpoint would be seen as controversial 15 to 20 years ago. However, through studies of crowdsourced programs and reward systems, this idea does not seem that radical now. I would ask readers and researchers of this work to consider ways in which to challenge their own orthodoxy. By doing so, they may find solutions to problems not previously envisaged.

We live in an age of endless data, it is essential to stop and reflect on the data we produce, and how this data can be best used, to derive a higher degree of business and user intelligence. We note that machine learning (and AI) inevitably will have a greater role to play in how the data we generate is consumed. As practitioners devise the next generation of solutions based on our endless streams of data, we also need to educate both end users and machine learning practitioners of the ethical implications of our data and derived solutions. The challenges ahead will be, in part philosophical and in part technical. 

% ---------------------------------------------------------------------------
% ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------
